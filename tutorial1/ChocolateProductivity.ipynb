{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian (hierarchical) modelling in practice\n",
    "\n",
    "## or: How much chocolate do I need to eat to be more productive\n",
    "\n",
    "In this tutorial we will explore principles of Bayesian modelling in practice, starting from some simple data and going all the way to a full Bayesian hierarchical modelling.\n",
    "\n",
    "The problem: I don't drink coffee. This is clearly not great for my productivity, so I need to figure out an alternative. I've been wondering if maybe chocolate would make me more productive, so I've taken some data (not really, but I kind of wish I had!). I'm also curious how *much* chocolate I ought to eat in order to be more productive. Too little, and it won't have an effect. Too much, and I might be too ill to get anything done. \n",
    "\n",
    "Let's see what we can find out!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports + Packages\n",
    "\n",
    "You might not have all the packages you need in order to follow this notebook. If you don't, here's some code that might help you install it. If you don't use `pip` to manage your packages (e.g. because you use Anaconda), you might want to do this in a command line instead, and then restart the notebook.\n",
    "\n",
    "If you're working in Colab, definitely remove the commenting from the last three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn\n",
    "#!pip install pandas\n",
    "#!pip install emcee\n",
    "#!pip install corner\n",
    "#!pip install pymc3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're running in Colab, comment out this line below\n",
    "%matplotlib notebook\n",
    "\n",
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# some style choices\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "\n",
    "import emcee\n",
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're in Colab, you'll want to clone the github repo and move into it in order to load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/dhuppenkothen/cargese2018_tutorials.git\n",
    "#%cd cargese2018_tutorials/tutorial1/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In either case, you should now be able to read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"chocolate_productivity_daniela.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've never used pandas `DataFrame`s before, they might take some time getting used to. One useful thing you can do is use the `head` method to take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data here is the grams that I ate in a day (in the column `grams`), and the productivity of that day (`prod`) as measured in lines of code or text in a paper. Because I suck at counting, there's some uncertainty in that number called `prod_err`. \n",
    "\n",
    "Let's plot what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "ax.errorbar(df[\"grams\"], df[\"prod\"], yerr=df[\"prod_err\"], fmt=\"o\", markersize=5, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A single person\n",
    "\n",
    "Let's calculate the chocolate consumption for a single person. This is drawn from a Lorentzian function,\n",
    "\n",
    "$$\n",
    "L(x) = \\frac{A}{\\pi} \\frac{\\gamma/2}{(x-x_0)^2 + (\\gamma/2)^2}\n",
    "$$\n",
    "\n",
    "where $A$ is the amplitude, $x_0$ is the centre of the Lorentzian, and $\\gamma$ is the width parameter. A Lorentzian is essentially a Gaussian with broader wings, which I chose here because I didn't want to overuse the Gaussian, which will appear in several other places already.\n",
    "\n",
    "**Caution**: By default, this function is normalized so that the integral of the Lorentzian integrates to 1. In order to make the amplitude correspond to the number of lines written, you need to multiply it by $\\pi \\gamma/2$!\n",
    "\n",
    "Let's write a function to make a Lorentzian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lorentzian(x, amp, x0, gamma):\n",
    "    ## add your code here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 5, 1000)\n",
    "\n",
    "x0 = 2.5\n",
    "gamma = 0.5\n",
    "amp = 1.0\n",
    "\n",
    "ll = lorentzian(x, amp, x0, gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "\n",
    "ax.plot(x, ll, lw=2, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope that looks like a Lorentzian. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Inference for a single person\n",
    "\n",
    "Let's now do parameter inference for a single person.\n",
    "\n",
    "We're going to need to define the likelihood and some priors.\n",
    "\n",
    "For the likelihood, we're going to assume Gaussian uncertainties, so a Gaussian likelihood, defined as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\theta) = \\prod_{i=1}{N}\\left[\\frac{1}{\\sqrt{2\\pi\\sigma_i^2}}\\exp{\\left(-\\frac{(y_i - f(x_i, \\theta))^2}{2\\sigma_i^2} \\right)}   \\right]\n",
    "$$\n",
    "\n",
    "where $\\theta = \\{A, x_0, \\gamma \\}$ is the set of parameters, $f(x_i, \\theta)$ is the model function (i.e. the Lorentzian, $\\sigma_i$ is the uncertainty in the measurement $y_i$.\n",
    "\n",
    "**Exercise 1**: Write down the probabilistic graphical model for this problem.\n",
    "\n",
    "\n",
    "**Exercise 2**: Now define the likelihood for your model in a function or class.\n",
    "\n",
    "**Hints**:\n",
    "* You'll want to implement the *logarithm* of the likelihood, not the likelihood itself, to avoid  numerical errors\n",
    "* You might also want to check whether the value of the likelihood is finite, and if not, return -np.inf (i.e. an improbably small value), in order to avoid issues with NaNs\n",
    "* Write your log-likelihood such that it takes the *logarithm* of the amplitude . Can you think of a good reason for this? Discuss with your partner!\n",
    "\n",
    "Below, I've provided a simple structure for a likelihood class. I like writing likelihoods in classes, because it means I can call `mylikelihood(parameters)` and it will know about the data automatically! \n",
    "\n",
    "\n",
    "If you're more comfortable writing a function, just do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussLogLike(object):\n",
    "    \n",
    "    def __init__(self, x, y, yerr):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yerr = yerr\n",
    "        \n",
    "        # hard-coded model for this problem,\n",
    "        # but could be a parameter\n",
    "        self.model = lorentzian\n",
    "        \n",
    "    def evaluate(self, pars, neg=False):\n",
    "        \"\"\"\n",
    "        Evaluate the likelihood\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        pars : iterable\n",
    "            The list of parameters for the Lorentzian function\n",
    "            \n",
    "        neg : bool\n",
    "            A boolean variable. If True, return the *negative* \n",
    "            log-likelihood (useful for optimization, which are \n",
    "            minimization routines), otherwise just return the \n",
    "            log-likelihood itself\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # get the parameters out of the array\n",
    "        # make sure the amplitude is exponentiated\n",
    "        \n",
    "        \n",
    "        # calculate the mean model\n",
    "\n",
    "        \n",
    "        # calculate the log-likelihood\n",
    "        \n",
    "        \n",
    "        # this code ensures that if the likelihood \n",
    "        # is NaN, it becomes negative infinite \n",
    "        # (so really, really unlikely)\n",
    "        if not np.isfinite(loglike):\n",
    "            loglike = -np.inf\n",
    "            \n",
    "        if neg:\n",
    "            return -loglike\n",
    "        else:\n",
    "            return loglike\n",
    "        \n",
    "    def __call__(self, pars, neg=False):\n",
    "        \"\"\"\n",
    "        The __call__ method allows to call the object \n",
    "        directly after instantiation. \n",
    "        \n",
    "        Example:\n",
    "        >>> mylikelihood = GaussLogLike(xdata, ydata, yerrors, lorenztian)\n",
    "        >>> pars = [2.0, 10.0, 3.0]\n",
    "        >>> print(mylikelihood(pars))\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.evaluate(pars, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with our test data. \n",
    "\n",
    "Note: the lines below will work this way only with the class above. \n",
    "If you've written a function, replace them with whatever you need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the likelihood object\n",
    "# using the data\n",
    "llike = GaussLogLike(grams1, prod1, prod_err1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Guess some parameters based on the plot you've made of the data and print the log-likelihood for those parameters. Note the result. Then define some other parameters and try again. What do you notice? \n",
    "\n",
    "**Hint**: remember that we've defined our amplitude in our likelihood as the *logarithm* of the actual amplitude!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some parameters here\n",
    "\n",
    "\n",
    "# calculate the log-likelihood like so:\n",
    "print(llike(my_parameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool, that hopefully works. For full Bayesian inference, however, we need some priors. Based on your probabilistic graphical model above, you should have an idea what parameters you'll need to define priors for. \n",
    "\n",
    "**Exercise**: Discuss priors with your group! What kind of priors do you think could work for the parameters here? Are there constraints on the parameters, e.g. values they cannot be allowed to take? What assumption will those priors make about the process and your data?\n",
    "\n",
    "\n",
    "Below, I've made another class, this time for the posterior. It uses the likelihood we've defined above along with some priors in order to give you a posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussPosterior(object):\n",
    "    \n",
    "    def __init__(self, x, y, yerr):\n",
    "        \"\"\"\n",
    "        This code is called when you make an object of this class.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : iterable\n",
    "            The x-coordinate of your data\n",
    "    \n",
    "        y : iterable\n",
    "            The y-coordinate of your data\n",
    "            \n",
    "        yerr : iterable\n",
    "            The uncertainties on your y-values\n",
    "        \n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.yerr = yerr\n",
    "        \n",
    "        # hard-coded model for this problem,\n",
    "        # but could be a parameter\n",
    "        self.model = lorentzian\n",
    "        \n",
    "        # use the likelihood definition from above in here \n",
    "        # to instantiate the likelihood\n",
    "        self.loglikelihood = GaussLogLike(self.x, self.y, self.yerr)\n",
    "        \n",
    "        # this calls the method below, which sets the priors so we don't \n",
    "        # have to do this every time (which would be computationally expensive)\n",
    "        self._set_logprior_dist()\n",
    "\n",
    "    def _set_logprior_dist(self):\n",
    "        \"\"\"\n",
    "        Set the distributions for the log-priors in advance to avoid overhead.\n",
    "        \n",
    "        Hint: the distributions in scipy.stats come in handy here\n",
    "        \"\"\"\n",
    "        \n",
    "        # here's an example of how you could define some distributions.\n",
    "        # first, a normal distribution, `loc` is the mean, `scale` is the standard deviation\n",
    "        # self.a_dist = scipy.stats.norm(loc=10, scale=1)\n",
    "        \n",
    "        # here's a uniform distribution\n",
    "        # note: here, `loc` is the left edge of the distribution, `scale` the width \n",
    "        # of the non-zero interval! So the example below is nonzero between 5 and 15\n",
    "        # self.b_dist = scipy.stats.uniform(loc=5, scale=10)\n",
    "\n",
    "        # prior for the log-amplitude\n",
    "        self.p_logamp = # add your definition here\n",
    "        \n",
    "        # prior for x0\n",
    "        self.p_x0 = # add your definition here\n",
    "        \n",
    "        # prior for gamma\n",
    "        self.p_gamma = # add your definition here\n",
    "    \n",
    "\n",
    "    def logprior(self, pars):\n",
    "        \"\"\"\n",
    "        Calculate the logarithm of the prior, assuming you've stored scipy.stats distributions\n",
    "        in `_set_logprior()` as attributes above. Uses the `logpdf` to calculate the logarithm \n",
    "        of the probability density function for each parameter.\n",
    "        \n",
    "        If you have defined your priors differently, you'll need to change this!\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.p_logamp.logpdf(pars[0]) + self.p_x0.logpdf(pars[1]) + self.p_gamma.logpdf(pars[2])\n",
    "\n",
    "    def logposterior(self, pars, neg=False):\n",
    "        \"\"\"\n",
    "        Calculate the log-posterior, which is just the sum of the log-prior and \n",
    "        the log-likelihood for the parameters.\n",
    "        \n",
    "        We play the same game as in the likelihood above: if the log-posterior \n",
    "        isn't finite, make it infinitely unlikely (-infinity), and return the \n",
    "        *negative* log-posterior if `neg=True`\n",
    "        \n",
    "        \"\"\"\n",
    "        lpost = self.loglikelihood(pars, neg=False) + self.logprior(pars)\n",
    "        \n",
    "        if not np.isfinite(lpost):\n",
    "            lpost = -np.inf\n",
    "\n",
    "        if neg: \n",
    "            return -lpost\n",
    "        else:\n",
    "            return lpost\n",
    "    \n",
    "    def __call__(self, pars, neg=False):\n",
    "        return self.logposterior(pars, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpost = GaussPosterior(grams1, prod1, prod_err1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Print the posterior for the same range of parameters as above. Have things changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum-A-Posteriori Fits\n",
    "\n",
    "One useful thing to do is optimize the log-posterior. This is the Bayesian version of maximum likelihood fitting, which you may have heard of, but now includes the information added by the prior.\n",
    "\n",
    "In python we can use `scipy.optimize` for this.\n",
    "\n",
    "**Hint**: Be aware that optimization routines are generally *minimization* routines. So instead of maximizing the posterior, we need to minimize the negative posterior. This is why we added a `neg` keyword to our class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = scipy.optimize.minimize(lpost, true_pars1_log+1, method=\"L-BFGS-B\", args=(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should print out `res.message`, because it'll tell you whether the algorithm has failed. Optimization can in general be quite difficult, and you can fall into many different pitfalls. In particular, they are prone to get stuck in *local* minima, i.e. you think you've converged to the actual minimum, but you're stuck somewhere away from it in parameter space. Sometimes, what can help with this is to run the optimizer several times with different starting parameters. You can also try to use a different optimization algorithm, since different algorithms work differently well for different problems.\n",
    "\n",
    "In any case, you should print out `res.message`, which will give you *some* information about whether your optimization was successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best-fit parameters are stored in `res.x`. You should print those, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Plot your data with the best-fit model shown in the same figure. Remember that your amplitude in the best-fit parameters is the *logarithm* of the parameter that goes into your `lorentzian` function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, your fit should go through most of the data points. If not, maybe try again with a different set of starting parameters.\n",
    "\n",
    "### MCMC\n",
    "\n",
    "A point estimate of your \"best-fit\" parameters is often not super helpful in learning something useful about your problem. For doing inference, we often want to know the full posterior probability density, which is, for most practical purposes, impossible to calculate analytically.\n",
    "\n",
    "In the lecture yesterday, you've learned about MCMC. MCMC is used to *sample* the posterior in order to map out the posterior distribution efficiently. This is not an MCMC tutorial (but a nice one can be found [here](https://github.com/davidwhogg/mcmc)).\n",
    "\n",
    "If you have the time, I'd really recommend writing your own [Metropolis-Hastings sampler](https://en.wikipedia.org/wiki/Metropolisâ€“Hastings_algorithm). It takes a while, and can be a bit fiddly, but it is super instructive! Writing your own sampler will teach you more about MCMC than any tutorial ever will!\n",
    "\n",
    "There are many, many different types of sampling algorithms out there. Some (non-exhaustive) keywords for you to explore:\n",
    "\n",
    "* ensemble MCMC\n",
    "* simulated annealing/parallel tempering\n",
    "* nested sampling (and variants diffusive nested sampling and dynamical nested sampling)\n",
    "* slice sampling\n",
    "* Hamiltonian Monte Carlo\n",
    "* Sequential Monte Carlo\n",
    "\n",
    "Much like with optimization algorithms, different MCMC algorithms solve different problems differently well, and how well one does might also depend on the time you can spend. A very well-tuned Metropolis-Hastings sampler might work better for you than a general ensemble MCMC method. Note that there are problems that are hard for *all* samplers. One problem is, for example, a posterior with very narrow, well-separated peaks. Finding all of those peaks is very hard no matter what algorithm you use.\n",
    "\n",
    "Here, right now, we're not going to do this; we are going to use a fairly robust MCMC package called `emcee` to do some inference on our posterior probability density.\n",
    "\n",
    "Most MCMC samplers need to be *initialized* in some way, that is, you need to give them the parameter values where the chain should start. We're going to use the results of the optimization earlier as an initialization. This can make your convergence faster if you're reasonably sure that your optimizer isn't super far off the actual peak of the posterior.\n",
    "\n",
    "We're going to initialize our MCMC chains (there'll be several) using a *multi-variate normal distribution*, using the best-fit values and the covariance from the optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_opt = # add code for the best-fit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance is stored as `hess_inv` (inverse Hessian) in the `res` object, but in a sparse matrix format, so we'll need to convert it to an actual array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = res.hess_inv.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In emcee, the chains are generally called *walkers*. We'll use 36, and we'll run for 1000 iterations.\n",
    "Before that, however, we need to *burn in* our chains, i.e. run it for a while and hope that at the end of this *burn-in period*, our walkers have converged to the true posterior. Since this is a fairly simple problem with just three parameters, we'll try 2000 steps. In practice, we never know whether this is true, though there are some statistics you can use to explore this. \n",
    "\n",
    "One method is to look at the *autocorrelation time*, the number of steps you need to go until you reach an uncorrelated sample. If this time is very small, then almost all samples are uncorrelated, and your chains are doing a random walk through parameter space (and not sample the actual posterior). If the autocorrelation time is very large, then your chains are stuck somewhere and aren't actually moving about parameter space at all, and you're not converged, either.\n",
    "\n",
    "Another method to assess convergence is the Gelman-Rubin statistic, which you can find in [this book](http://www.stat.columbia.edu/~gelman/book/) (which is generally an excellent reference to have, though not really a starting point for beginners), or alternatively also in the documentation of [this package](https://pymc-devs.github.io/pymc/modelchecking.html). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwalkers = # number of walkers\n",
    "burnin =  # number of samples for burn-in\n",
    "niter =  # number of samples in production\n",
    "\n",
    "ndim = 3 # the number of parameters\n",
    "\n",
    "# initialize the sampler\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, lpost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to draw starting positions from a multivariate normal distribution. As we've said above, we'll take the mean and the covariance from the optimization, and we'll need to draw one for each walker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = # starting positions for the walkers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're set up to run the MCMC sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, prob, rstate1 = sampler.run_mcmc(p0, burnin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One helpful diagnostic before calculating anything is to make what's called a *trace plot*. In this plot, you simply plot the value of each parameter for each chain as a function of the iterations. \n",
    "\n",
    "If your chains are converged, they should look like white noise (i.e. randomly distributed around a mean value). If there are significant trends, or parts where the chains look completely flat, they're likely not converged and you should run longer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(ndim):\n",
    "    \n",
    "    # plot a time series of each parameter versus iterations\n",
    "    # hint: the quantity you want to plot is sampler.chain[:,:,i].T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your chains don't look converged, run longer!\n",
    "\n",
    "If they have, we're going to throw away the samples we've drawn so far, but keep the last position where the sampler has been in order to initialize our production run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, prob, rstate1 = sampler.run_mcmc(pos, niter, rstate0=rstate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a trace of the walkers again, using the same code as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful plot to make once you think you have a reasonably good sample from the posterior is a so-called corner plot or pair plot, which plots the histogram of the marginal distribution for each parameter on the diagonal, and a scatter plot (or kernel density estimate) of each parameter versus each other parameter on the off-diagonal. This can help get an idea of what the posterior looks like (since we're generally not great at visualizing multi-dimensional surfaces in our head).\n",
    "\n",
    "A nice version of this kind of plot is implemented in seaborn's [pairplot](https://seaborn.pydata.org/examples/scatterplot_matrix.html). Another nice version is implemented in the package `corner`, which you should have installed above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the chains from all the walkers together\n",
    "flatchain = sampler.flatchain.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "before plotting, exponentiate the amplitude so that we plot the amplitude itself rather than the log-amplitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatchain_exp = # exponentiate the amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner.corner(flatchain_exp);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so this gives me a single distribution for a single person.\n",
    "\n",
    "## Inferring Population Parameters (With Probabilistic Programming)\n",
    "\n",
    "I have not done this experiment alone, of course! I got all my colleagues in on the game, and made them all eat chocolate and record their productivity for a month (again, not really, but they probabily wish I had)!\n",
    "\n",
    "What we're really interested in is whether my chocolate consumption generalizes to other people, and whether we can make the whole institute more productive by giving everyone chocolate!\n",
    "\n",
    "So we're interested in the values of `x0` for the entire population of our institute, and what this population looks like. We could just run MCMC for each person, and then histogram the results, but maybe we know more than that! Perhaps we know (from prior research on chocolate) that chocolate definitely causes an increase in productivity in everyone. Perhaps we also know that a human can only eat so much chocolate before getting sick. Perhaps we think that the productivity values might all cluster around the same value. We can use that prior information in order to *jointly* model all people together. \n",
    "\n",
    "The data for this problem is in this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"chocolate_productivity.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Inference for the hierarchical model\n",
    "\n",
    "In a hierarchical model, we want to learn something about the *population*, rather than any individual. In the model for a single person, we assumed that we had some prior distribution, e.g. for the peak productivity, and then inferred what the peak productivity for that one person (me) was. \n",
    "\n",
    "In the hierarchical model, we can't assume that everyone has the same peak productivity (some people might like chocolate more than others), but we can assume that the peak productivity parameters for each person come from some distribution (which itself may be related to some underlying physical process we're interested in, let's say the conversion rate of chocolate to brainpower). We're going to infer the *parameters* of that distribution along with the parameters of all the individual people in my sample. \n",
    "\n",
    "In our model for a single person, we had\n",
    "\n",
    "$$\n",
    "p(\\theta | y) \\propto p(y | \\theta) p(\\theta)\n",
    "$$\n",
    "\n",
    "where $\\theta = \\{\\log(A), x_0, \\log(\\gamma)\\}$. Instead of the rather uninformative flat priors on all of the parameters we've assumed above, we're going to assume that the peak productivity $x_0$ and the width $\\log(\\gamma)$ follow normal distributions with parameters $\\alpha = \\{\\mu_x0, \\sigma_x0, \\mu_\\gamma, \\sigma_\\gamma\\}$. These parameters $\\alpha$ are commonly called *hyperparameters*. Our model is getting slightly more complex, because now we have\n",
    "\n",
    "$$\n",
    "p(\\theta, \\alpha | y) \\propto p(y | \\theta) p(\\theta | \\alpha) p(\\alpha) \\; .\n",
    "$$\n",
    "\n",
    "Notice how the likelihood $p(y | \\theta)$ still only depends on $\\theta$ (not on $\\alpha$, but $\\alpha$ now controls the *prior* distribution for the parameters in $\\theta$. In order to infer the parameters $\\alpha$, we need to give them priors as well!\n",
    "\n",
    "**Exercise**: Draw a probabilistic graphical model for the hierarchical problem.\n",
    "\n",
    "We now want to learn something about the posterior probability for the parameters for each person along with the parameters for the whole population. Again, we turn to sampling to do this. There's a powerful way to do this in many places called *Gibbs sampling*, which we're not going to talk about today (but look it up! it's super useful!).\n",
    "\n",
    "We're going to use Hamiltonian Monte Carlo instead. This sampling algorithm uses *gradients* in your probability distribution to efficiently sample the space (usually much more efficient than Metropolis-Hastings, for example). But it requires that you *can* actually calculate gradients in your problem. This is often the case (and definitely works in our example above), but if your physics model includes e.g. numerical simulations, it might not be. \n",
    "\n",
    "A nice introduction into Hamiltonian Monte Carlo can be found in [this paper](https://arxiv.org/abs/1701.02434). There's also a nice blog post that's a little more whimsical [here](http://elevanth.org/blog/2017/11/28/build-a-better-markov-chain/).\n",
    "\n",
    "The package we use here is `pymc3`, but there are others out there (look e.g. at [STAN](http://mc-stan.org) or [Edward](http://edwardlib.org)).\n",
    "\n",
    "Note that STAN and Edward and PyMC3 are more than just samplers. They are packages that define *probabilistic programming grammars*, i.e. structures that make it easy to implement probabilistic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a model for a single person using probabilistic programming first. This is going to be much less verbose than all the code we've written above.\n",
    "\n",
    "First, let's extract a single person from our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = df.loc[df.name == \"Daniela\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_data = c_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should extract the productivity, the corresponding grams of chocolate and the uncertainties on our productivity measurements. \n",
    "\n",
    "**Hint**: these probably need to be converted to numpy arrays, because pymc3 won't deal well with pandas `Series` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productivity = #\n",
    "grams = #\n",
    "\n",
    "prod_err = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of people\n",
    "n_names = len(df[\"name_id\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get the error `\"TypeError: can't pickle CVM objects\"` when running the model below, then you've hit a well-known issue with the currently released version of `pymc3`. This is fixed in the current master branch, which you can install by uncommenting the following code (you might need to restart the notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install -U git+https://github.com/pymc-devs/pymc3.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as chocolate_model:\n",
    "    # first, let's define some priors\n",
    "    # here's an example:\n",
    "    #a = pm.Normal('alpha', mu=0, sd=1)\n",
    "    \n",
    "    # prior for the log-amplitude: same as in your model above\n",
    "    log_amp = #\n",
    "    \n",
    "    # prior for the width: same as in your model above\n",
    "    gamma = #\n",
    "    \n",
    "    # prior for the peak productivity: same as in your model above\n",
    "    x0 = #\n",
    "\n",
    "    # estimate the model for the parameters drawn\n",
    "    # use the variables you've just defined above as your \n",
    "    # parameters and stick them into your Lorentzian\n",
    "    \n",
    "    prod_est = # calculate the model productivity based on the Lorentzian\n",
    "    \n",
    "    # Data likelihood: Because we're using a Gaussian likelihood, this should be a normal distribution\n",
    "    # which takes the estimated productivity as mu, the uncertainties \n",
    "    # of the productivity as standard deviation, and the \n",
    "    # `observed` keyword should be set to the actual values of the productivity\n",
    "    # for one person\n",
    "    y_like = #\n",
    "\n",
    "    # Inference button (TM)!\n",
    "    indiv_trace = pm.sample(progressbar=True, steps=5000, chains=10, cores=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dictionary with the true parameters (which, ahem, I've stored in the data array with your data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pars = {\"log_amp\": np.log(c_data[\"true_amp\"].unique()), \n",
    "             \"x0\": c_data[\"true_x0\"].unique(), \n",
    "             \"gamma\": c_data[\"true_gamma\"].unique()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMC3 has an in-built method to make trace plots (and also plot the marginalized posterior distribution for each parameter). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(indiv_trace, lines=true_pars);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull out just the `x0` parameter for this model, for use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_indiv = indiv_trace.x0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we can set up the hierarchical model. A nice introduction in how to set up a hierarchical model with pymc3 can be found [here](https://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/).\n",
    "\n",
    "In the example above, we set e.g. the parameters of the prior for `x0` to actual *numbers*. However, in our new hierarchical model, these will be variables, too, which themselves are drawn from statistical distributions.\n",
    "\n",
    "In our hierarchical model, the prior distribution for `x0` is actually something that tells us something interesting about how the productivity of a *population* of people changes if you give them chocolate. \n",
    "\n",
    "To make our lives easier, we're going to *only* consider the parameters for the distribution of `x0`, and assume we know the parameters for the prior of `log_gamma` and `log_amp`. \n",
    "\n",
    "First, we're going to need to manipulate our data a bit to make it work, since we're now working with the full distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all productivity values for all people\n",
    "productivity = \n",
    "\n",
    "# all uncertainties for all people\n",
    "prod_err = \n",
    "\n",
    "# all x-values for all people\n",
    "grams = \n",
    "\n",
    "# indices for assigning the parameters correctly, stored in `name_id`\n",
    "prod_idx = np.array(df_all[\"name_id\"])\n",
    "\n",
    "# number of people in our population\n",
    "n_names = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up the model similarly as above, just with additional priors for the parameters of the priors for `x0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pm.Model() as hierarchical_chocolate_model:\n",
    "    # here's an example of how to define a random variable in PyMC3\n",
    "    #a = pm.Normal('alpha', mu=0, sd=1)\n",
    "    \n",
    "    # prior for the log-amplitude\n",
    "    log_amp = # same of before\n",
    "    \n",
    "    # prior for the log-width\n",
    "    gamma = # same as before\n",
    "    \n",
    "    # we're going to use a normal distribution for the distribution\n",
    "    # of x0\n",
    "    # this distribution has a mean and a standard deviation\n",
    "    # for which we choose a uniform distribution for the mean \n",
    "    # and a Half-Cauchy distribution (so it's positive) for the standard\n",
    "    # deviation with a beta-parameter of 5\n",
    "    \n",
    "    mu_x0 = #\n",
    "    sd_x0 = #\n",
    "    \n",
    "    # prior for the peak productivity\n",
    "    x0 = # normal distribution using the `mu_x0` and `sd_x0` variables above for mean and std deviation\n",
    "\n",
    "    # estimate the model for the parameters drawn\n",
    "    \n",
    "    # assign the parameters for the correct person to the \n",
    "    # right position in an array corresponding to *all* \n",
    "    # gram/productivity measurements\n",
    "    amp_array = np.exp(log_amp[prod_idx])\n",
    "    gamma_array = gamma[prod_idx]\n",
    "    x0_array = x0[prod_idx]\n",
    "    \n",
    "    # definition of the Lorentzian\n",
    "    prod_est = # model values for all pairs of grams/productivity for all people\n",
    "    \n",
    "    # Data likelihood: this should be a normal distribution\n",
    "    # which takes the estimated productivity as mu, the uncertainties \n",
    "    # of the productivity as standard deviation, and the \n",
    "    # `observed` keyword should be set to the actual values of the productivity\n",
    "    # for one person\n",
    "    y_like = #\n",
    "\n",
    "    # Inference button (TM)!\n",
    "    hierarchical_trace = pm.sample(progressbar=True, steps=1000, chains=6, cores=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make an array of the true parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot twist: the true values for the individual people in \n",
    "# our list are in the DataFrame you loaded!\n",
    "true_log_amp = np.log(df_all[\"true_amp\"].unique())\n",
    "true_gamma = df_all[\"true_gamma\"].unique()\n",
    "true_x0 = df_all[\"true_x0\"].unique()\n",
    "\n",
    "# These are the true values of the distribution of \n",
    "# peak productivities I didn't tell you about!\n",
    "true_mu_x0 = 25.0\n",
    "true_sd_x0 = 1.0\n",
    "\n",
    "true_pars = {\"log_amp\": true_log_amp, \"gamma\":true_gamma,\n",
    "             \"x0\": true_x0, \"mu_x0\":true_mu_x0, \"sd_x0\": true_sd_x0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can make a trace-plot of all of the parameters with their true values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.traceplot(hierarchical_trace, lines=true_pars);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also extract the `x0` for the first person from here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_hier = hierarchical_trace.x0[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare the marginalized posterior of `x0` from the single-person model to the marginalized posterior of `x0` for the hierarchical model.\n",
    "\n",
    "Plot the two distributions and compare.\n",
    "\n",
    "**Hint**: The seaborn function [`distplot`](https://seaborn.pydata.org/examples/distplot_options.html) allows you to display this kind of data in several different ways. I personally like the combination of a histogram and a kernel density estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now see two things from your trace plots and your histogram of `x0` for one person: one, we did pretty well at determining the population parameters themselves. Secondly, in the plot above, you should see that the posterior for `x0` shrunk (I hope?) in the hierarchical model compared to the model where we only had one person. This is called *Bayesian shrinkage*, and happens because the population now informs the posterior for our individual members.\n",
    "\n",
    "### Bonus Advanced Problem\n",
    "\n",
    "Use the methods from the lectures (predictive sample re-use and posterior predictive checks) to check how well your model works in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
